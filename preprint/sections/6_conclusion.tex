\vspace{-0.75\baselineskip}
\section{Conclusion}
\label{sec:conclusion}
\vspace{-0.75\baselineskip}
We have presented~\ourname{}, a novel approach to accelerating the generative process of Discrete Flow Models (DFMs) through a lightweight preprocessing step performed prior to training. Our preprocessing, which couples source and target samples, requires only up to 1.7\% of the base model training cost, making it at least 20Ã— more efficient than finetuning, while still achieving comparable or even superior performance. The key enabler is the closed-form inversion, which eliminates the need for a pretrained teacher model.